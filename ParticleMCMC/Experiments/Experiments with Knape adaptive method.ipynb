{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')  # hide warnings \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import particles.mcmc as mcmc\n",
    "import particles.state_space_models as ssm\n",
    "import particles.distributions as dists\n",
    "from particles.core import SMC\n",
    "from particles import smc_samplers as ssp\n",
    "import seaborn\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "path = r'C:\\Users\\dobau\\Desktop\\3A ENSAE\\S1\\Hidden Markov Chain and MCMC\\Project\\res'\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the three steps Adaptative method proposed by Knape & De Valpine (2012). We focus our experiments on the three models detailed in the paper: Random Walk (M3), Exponential growth (M2) and Logistic Diffusion with Euler Discretization (M1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = 4000\n",
    "n_iter = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Walk model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████▌                                                              | 627/3000 [00:22<02:07, 18.63it/s]"
     ]
    }
   ],
   "source": [
    "prior_RW = {'tau': dists.Uniform(a=0.,b=1.),'sigma': dists.Uniform(a=0.,b=10.)}\n",
    "p_RW = dists.StructDist(prior_RW)\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    pmmh_RW = pickle.load(open( os.path.join(path,\"RW_model_Adapt.pkl\"), \"rb\" ))\n",
    "else:\n",
    "    new_pmmh_RW= AdaptivePMMH(ssm_cls=RandomWalk2D, prior=p_RW, data=y, Nx=n_particles, niter=3000, adaptive=True,\n",
    "                          m1=1000, m2=2000, update_interv=100, w01=0.4, w02=0.5, w1=0.8, k0=5., k1=5.)\n",
    "    new_pmmh_RW.run()\n",
    "    pickle.dump(pmmh_RW, open( os.path.join(path,\"RW_model_Adapt.pkl\"), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_metrics(new_pmmh_RW)\n",
    "plot_theta(prior_RW,new_pmmh_RW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distplot(prior_RW, new_pmmh_RW, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulRW_new = get_trajectories(N=100, start=2000, model='RW', pmmh=new_pmmh_RW, n_particles=10000)\n",
    "plot_posterior_trajectories(simulRW_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Growth (M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_EG = {'tau': dists.Uniform(a=0.,b=1.),\n",
    "             'sigma': dists.Uniform(a=0.,b=10.), 'r':dists.Uniform(a=-10., b=10.)}\n",
    "\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    pmmh_Ldrift = pickle.load(open( os.path.join(path,\"EG_model_Adapt.pkl\"), \"rb\" ))\n",
    "else:\n",
    "    p_EG = dists.StructDist(prior_EG)\n",
    "    new_pmmh_EG= AdaptivePMMH(ssm_cls=LDPDrift, prior=p_EG, data=y, Nx=n_particles, niter=3000, adaptive=True,\n",
    "                          m1=1000, m2=2000, update_interv=100, w01=0.4, w02=0.5, w1=0.8, k0=5., k1=5.)\n",
    "    new_pmmh_EG.run()\n",
    "    pickle.dump(pmmh_Ldrift, open( os.path.join(path,\"EG_model_Adapt.pkl\"), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(new_pmmh_EG)\n",
    "plot_theta(prior_EG,new_pmmh_EG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distplot(prior_EG, new_pmmh_EG, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulEG_new = get_trajectories(N=100, start=2000, model='LDrift', pmmh=new_pmmh_EG, n_particles=10000)\n",
    "plot_posterior_trajectories(simulEG_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Diffusion Process with Euler discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_LDP = {'tau': dists.Uniform(a=0.,b=1.), 'b': dists.Uniform(a=0., b=1.),\n",
    "             'sigma': dists.Uniform(a=0.,b=10.), 'r':dists.Uniform(a=-10., b=10.)}\n",
    "\n",
    "load_model = False\n",
    "\n",
    "if load_model:\n",
    "    new_pmmh_LDP = pickle.load(open( os.path.join(path,\"LDP_model_Adapt.pkl\"), \"rb\" ))\n",
    "else:\n",
    "    p_LDP = dists.StructDist(prior_LDP)\n",
    "    new_pmmh_LDP= AdaptivePMMH(ssm_cls=LDEuler, prior=p_LDP, data=y, Nx=n_particles, niter=5000, adaptive=True,\n",
    "                          m1=4000, m2=4999, update_interv=1000, w01=0.4, w02=0.5, w1=0.8, k0=25., k1=5.)\n",
    "    new_pmmh_LDP.run()\n",
    "    pickle.dump(new_pmmh_LDP, open( os.path.join(path,\"LDP_model_Adapt.pkl\"), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(new_pmmh_LDP)\n",
    "plot_theta(prior_LDP,new_pmmh_LDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distplot(prior_LDP, new_pmmh_LDP, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulLDP_new = get_trajectories(N=100, start=5000, model='LDP', pmmh=new_pmmh_LDP, n_particles=10000)\n",
    "plot_posterior_trajectories(simulLDP_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
